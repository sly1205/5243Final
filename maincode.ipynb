{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lizard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_dir = r'D:/Desktop/5243Bianca/Final Project/Dorsal/Dorsal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation complete. 56 training images and 14 testing images.\n",
      "Created 0 augmented images.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "def prepare_dataset(input_dir, output_dir, test_size=0.2):\n",
    "    os.makedirs(os.path.join(output_dir, 'train', 'lizard'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'train', 'background'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'test', 'lizard'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'test', 'background'), exist_ok=True)\n",
    "    \n",
    "    images = [f for f in os.listdir(input_dir) if f.endswith(('.jpg', '.jpeg', '.png','JPG'))]\n",
    "    train_images, test_images = train_test_split(images, test_size=test_size, random_state=42)\n",
    "    \n",
    "    process_image_set(input_dir, train_images, os.path.join(output_dir, 'train'))\n",
    "    process_image_set(input_dir, test_images, os.path.join(output_dir, 'test'))\n",
    "    \n",
    "    print(f\"Dataset preparation complete. {len(train_images)} training images and {len(test_images)} testing images.\")\n",
    "\n",
    "def process_image_set(input_dir, image_list, output_dir):\n",
    "    for img_name in image_list:\n",
    "        img_path = os.path.join(input_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not read {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        corrected_img = color_correction(img)\n",
    "        lizard_mask, lizard_img = extract_lizard(corrected_img)\n",
    "        \n",
    "        lizard_output_path = os.path.join(output_dir, 'lizard', img_name)\n",
    "        cv2.imwrite(lizard_output_path, lizard_img)\n",
    "        \n",
    "        background_img = create_background_image(corrected_img, lizard_mask)\n",
    "        background_output_path = os.path.join(output_dir, 'background', f\"bg_{img_name}\")\n",
    "        cv2.imwrite(background_output_path, background_img)\n",
    "\n",
    "def color_correction(img):\n",
    "    height, width = img.shape[:2]\n",
    "    colorchecker_roi = img[height//4:height//2, width//2:width-width//10]\n",
    "    result = img.copy()\n",
    "    gray_patch = colorchecker_roi[colorchecker_roi.shape[0]//2, colorchecker_roi.shape[1]//2]\n",
    "    \n",
    "    if np.max(gray_patch) > 0:\n",
    "        scale = 128 / np.mean(gray_patch)\n",
    "        result = cv2.convertScaleAbs(img, alpha=scale, beta=0)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def extract_lizard(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_lizard = np.array([20, 30, 50])\n",
    "    upper_lizard = np.array([40, 255, 255])\n",
    "    \n",
    "    lizard_mask = cv2.inRange(hsv, lower_lizard, upper_lizard)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    lizard_mask = cv2.morphologyEx(lizard_mask, cv2.MORPH_OPEN, kernel)\n",
    "    lizard_mask = cv2.morphologyEx(lizard_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    contours, _ = cv2.findContours(lizard_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        max_contour = max(contours, key=cv2.contourArea)\n",
    "        refined_mask = np.zeros_like(lizard_mask)\n",
    "        cv2.drawContours(refined_mask, [max_contour], 0, 255, -1)\n",
    "        lizard_mask = refined_mask\n",
    "    \n",
    "    lizard_img = img.copy()\n",
    "    background = np.ones_like(img) * 255\n",
    "    lizard_img = np.where(lizard_mask[:, :, np.newaxis] == 255, img, background)\n",
    "    \n",
    "    return lizard_mask, lizard_img\n",
    "\n",
    "def create_background_image(img, lizard_mask):\n",
    "    background_img = img.copy()\n",
    "    background_img[lizard_mask == 255] = [0, 0, 0]\n",
    "    return background_img\n",
    "\n",
    "def augment_dataset(input_dir, output_dir, n_augmentations=5):\n",
    "    import imgaug.augmenters as iaa\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    aug_seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Affine(\n",
    "            rotate=(-15, 15),\n",
    "            scale=(0.8, 1.2),\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}\n",
    "        ),\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "        iaa.AdditiveGaussianNoise(scale=(0, 0.05*255))\n",
    "    ])\n",
    "    \n",
    "    images = [f for f in os.listdir(input_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(input_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        for i in range(n_augmentations):\n",
    "            aug_img = aug_seq(image=img_rgb)\n",
    "            aug_img_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
    "            output_path = os.path.join(output_dir, f\"aug_{i}_{img_name}\")\n",
    "            cv2.imwrite(output_path, aug_img_bgr)\n",
    "    \n",
    "    print(f\"Created {len(images) * n_augmentations} augmented images.\")\n",
    "\n",
    "def main():\n",
    "    input_dir = \"D:/Desktop/5243Bianca/Final Project/Dorsal/Dorsal\"\n",
    "    processed_dir = \"D:/Desktop/5243Bianca/Final Project/Dorsal/processed_data/\"\n",
    "    augmented_dir = \"D:/Desktop/5243Bianca/Final Project/Dorsal/augmented_data/\"\n",
    "    \n",
    "    prepare_dataset(input_dir, processed_dir)\n",
    "    augment_dataset(os.path.join(processed_dir, 'train', 'lizard'), \n",
    "                    os.path.join(augmented_dir, 'lizard'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preparation complete. 56 training images and 14 testing images.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dir = \"D:/Desktop/5243Bianca/Final Project/Dorsal/Dorsal\"  # 包含原始图像的目录\n",
    "processed_dir = \"D:/Desktop/5243Bianca/Final Project/Dorsal/processed_data/\"  # 处理后的图像目录\n",
    "augmented_dir = \"D:/Desktop/5243Bianca/Final Project/Dorsal/augmented_data/\"  # 增强后的图像目录\n",
    "prepare_dataset(input_dir, processed_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory: D:/Desktop/5243Bianca/Final Project/middle_section\n",
      "Processed: IMG_1411.JPG\n",
      "Processed: IMG_1414.JPG\n",
      "Processed: IMG_1417.JPG\n",
      "Processed: IMG_1419.JPG\n",
      "Processed: IMG_1421.JPG\n",
      "Processed: IMG_1423.JPG\n",
      "Processed: IMG_1425.JPG\n",
      "Processed: IMG_1427.JPG\n",
      "Processed: IMG_1429.JPG\n",
      "Processed: IMG_1432.JPG\n",
      "Processed: IMG_1434.JPG\n",
      "Processed: IMG_1436.JPG\n",
      "Processed: IMG_1438.JPG\n",
      "Processed: IMG_1440.JPG\n",
      "Processed: IMG_1443.JPG\n",
      "Processed: IMG_1446.JPG\n",
      "Processed: IMG_1448.JPG\n",
      "Processed: IMG_1451.JPG\n",
      "Processed: IMG_1453.JPG\n",
      "Processed: IMG_1455.JPG\n",
      "Processed: IMG_1457.JPG\n",
      "Processed: IMG_1459.JPG\n",
      "Processed: IMG_1461.JPG\n",
      "Processed: IMG_1463.JPG\n",
      "Processed: IMG_1465.JPG\n",
      "Processed: IMG_1468.JPG\n",
      "Processed: P1010185.JPG\n",
      "Processed: P1010187.JPG\n",
      "Processed: P1010189.JPG\n",
      "Processed: P1010191.JPG\n",
      "Processed: P1010193.JPG\n",
      "Processed: P1010195.JPG\n",
      "Processed: P1010197.JPG\n",
      "Processed: P1010199.JPG\n",
      "Processed: P1010201.JPG\n",
      "Processed: P1010203.JPG\n",
      "Processed: P1010205.JPG\n",
      "Processed: P1010207.JPG\n",
      "Processed: P1010209.JPG\n",
      "Processed: P1010211.JPG\n",
      "Processed: P1010330.JPG\n",
      "Processed: P1010333.JPG\n",
      "Processed: P1010336.JPG\n",
      "Processed: P1010338.JPG\n",
      "Processed: P1010340.JPG\n",
      "Processed: P1010343.JPG\n",
      "Processed: P1010346.JPG\n",
      "Processed: P1010348.JPG\n",
      "Processed: P1010350.JPG\n",
      "Processed: P1010352.JPG\n",
      "Processed: P1010355.JPG\n",
      "Processed: P1010357.JPG\n",
      "Processed: P1010360.JPG\n",
      "Processed: YQ1401-D.JPG\n",
      "Processed: YQ1402-D.JPG\n",
      "Processed: YQ1403-D.JPG\n",
      "Processed: YQ1404-D.JPG\n",
      "Processed: YQ1405-D.JPG\n",
      "Processed: YQ1406-D.JPG\n",
      "Processed: YQ1407-D.JPG\n",
      "Processed: YQ1408-D.JPG\n",
      "Processed: YQ1409-D.JPG\n",
      "Processed: YQ1410-D.JPG\n",
      "Processed: YQ1411-D.JPG\n",
      "Processed: YQ1412-D.JPG\n",
      "Processed: YQ1413-D.JPG\n",
      "Processed: YQ1414-D.JPG\n",
      "Processed: YQ1415-D.JPG\n",
      "Processed: YQ1416-D.JPG\n",
      "Processed: YQ1417-D.JPG\n",
      "\n",
      "Completed! 70 images were processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define source and destination directories\n",
    "source_dir = r\"D:/Desktop/5243Bianca/Final Project/Dorsal/Dorsal\"\n",
    "destination_dir = r\"D:/Desktop/5243Bianca/Final Project/middle_section\"\n",
    "\n",
    "# Create destination directory if it doesn't exist\n",
    "if not os.path.exists(destination_dir):\n",
    "    os.makedirs(destination_dir)\n",
    "    print(f\"Created directory: {destination_dir}\")\n",
    "\n",
    "# Process all JPG files in the source directory\n",
    "def process_images():\n",
    "    count = 0\n",
    "    # List all files in source directory\n",
    "    for filename in os.listdir(source_dir):\n",
    "        # Check if the file is a JPG\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg')):\n",
    "            try:\n",
    "                # Construct full file paths\n",
    "                source_path = os.path.join(source_dir, filename)\n",
    "                destination_path = os.path.join(destination_dir, filename)\n",
    "                \n",
    "                # Open and process the image\n",
    "                with Image.open(source_path) as img:\n",
    "                    # Get dimensions\n",
    "                    width, height = img.size\n",
    "                    \n",
    "                    # Calculate crop boundaries\n",
    "                    # Remove the left 1/4 and right 1/2\n",
    "                    left_boundary = width // 4  # Left 1/4 removed\n",
    "                    right_boundary = width // 2  # Keep only up to the middle (removing right 1/2)\n",
    "                    \n",
    "                    # Crop to keep only the middle section\n",
    "                    middle_section = img.crop((left_boundary, 0, right_boundary, height))\n",
    "                    \n",
    "                    # Save the cropped image\n",
    "                    middle_section.save(destination_path)\n",
    "                    count += 1\n",
    "                    print(f\"Processed: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    print(f\"\\nCompleted! {count} images were processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70 images.\n",
      "Image IMG_1411.JPG - Predicted Class: 38\n",
      "Image IMG_1414.JPG - Predicted Class: 38\n",
      "Image IMG_1417.JPG - Predicted Class: 38\n",
      "Image IMG_1419.JPG - Predicted Class: 38\n",
      "Image IMG_1421.JPG - Predicted Class: 38\n",
      "Image IMG_1423.JPG - Predicted Class: 38\n",
      "Image IMG_1425.JPG - Predicted Class: 38\n",
      "Image IMG_1427.JPG - Predicted Class: 38\n",
      "Image IMG_1429.JPG - Predicted Class: 327\n",
      "Image IMG_1432.JPG - Predicted Class: 38\n",
      "Image IMG_1434.JPG - Predicted Class: 327\n",
      "Image IMG_1436.JPG - Predicted Class: 38\n",
      "Image IMG_1438.JPG - Predicted Class: 38\n",
      "Image IMG_1440.JPG - Predicted Class: 38\n",
      "Image IMG_1443.JPG - Predicted Class: 38\n",
      "Image IMG_1446.JPG - Predicted Class: 38\n",
      "Image IMG_1448.JPG - Predicted Class: 38\n",
      "Image IMG_1451.JPG - Predicted Class: 38\n",
      "Image IMG_1453.JPG - Predicted Class: 38\n",
      "Image IMG_1455.JPG - Predicted Class: 38\n",
      "Image IMG_1457.JPG - Predicted Class: 38\n",
      "Image IMG_1459.JPG - Predicted Class: 38\n",
      "Image IMG_1461.JPG - Predicted Class: 38\n",
      "Image IMG_1463.JPG - Predicted Class: 38\n",
      "Image IMG_1465.JPG - Predicted Class: 38\n",
      "Image IMG_1468.JPG - Predicted Class: 38\n",
      "Image P1010185.JPG - Predicted Class: 38\n",
      "Image P1010187.JPG - Predicted Class: 38\n",
      "Image P1010189.JPG - Predicted Class: 38\n",
      "Image P1010191.JPG - Predicted Class: 32\n",
      "Image P1010193.JPG - Predicted Class: 38\n",
      "Image P1010195.JPG - Predicted Class: 47\n",
      "Image P1010197.JPG - Predicted Class: 38\n",
      "Image P1010199.JPG - Predicted Class: 47\n",
      "Image P1010201.JPG - Predicted Class: 47\n",
      "Image P1010203.JPG - Predicted Class: 452\n",
      "Image P1010205.JPG - Predicted Class: 38\n",
      "Image P1010207.JPG - Predicted Class: 47\n",
      "Image P1010209.JPG - Predicted Class: 38\n",
      "Image P1010211.JPG - Predicted Class: 47\n",
      "Image P1010330.JPG - Predicted Class: 327\n",
      "Image P1010333.JPG - Predicted Class: 38\n",
      "Image P1010336.JPG - Predicted Class: 47\n",
      "Image P1010338.JPG - Predicted Class: 38\n",
      "Image P1010340.JPG - Predicted Class: 38\n",
      "Image P1010343.JPG - Predicted Class: 38\n",
      "Image P1010346.JPG - Predicted Class: 38\n",
      "Image P1010348.JPG - Predicted Class: 893\n",
      "Image P1010350.JPG - Predicted Class: 526\n",
      "Image P1010352.JPG - Predicted Class: 38\n",
      "Image P1010355.JPG - Predicted Class: 38\n",
      "Image P1010357.JPG - Predicted Class: 38\n",
      "Image P1010360.JPG - Predicted Class: 38\n",
      "Image YQ1401-D.JPG - Predicted Class: 38\n",
      "Image YQ1402-D.JPG - Predicted Class: 38\n",
      "Image YQ1403-D.JPG - Predicted Class: 38\n",
      "Image YQ1404-D.JPG - Predicted Class: 38\n",
      "Image YQ1405-D.JPG - Predicted Class: 38\n",
      "Image YQ1406-D.JPG - Predicted Class: 38\n",
      "Image YQ1407-D.JPG - Predicted Class: 38\n",
      "Image YQ1408-D.JPG - Predicted Class: 38\n",
      "Image YQ1409-D.JPG - Predicted Class: 327\n",
      "Image YQ1410-D.JPG - Predicted Class: 38\n",
      "Image YQ1411-D.JPG - Predicted Class: 327\n",
      "Image YQ1412-D.JPG - Predicted Class: 38\n",
      "Image YQ1413-D.JPG - Predicted Class: 38\n",
      "Image YQ1414-D.JPG - Predicted Class: 38\n",
      "Image YQ1415-D.JPG - Predicted Class: 38\n",
      "Image YQ1416-D.JPG - Predicted Class: 38\n",
      "Image YQ1417-D.JPG - Predicted Class: 38\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import os\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载 MobileNet 预训练模型\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# 加载 ImageNet 类别标签\n",
    "imagenet_classes_path = 'imagenet_classes.txt'\n",
    "if not os.path.exists(imagenet_classes_path):\n",
    "    import urllib.request\n",
    "    url = 'https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt'\n",
    "    urllib.request.urlretrieve(url, imagenet_classes_path)\n",
    "\n",
    "with open(imagenet_classes_path) as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# 图像预处理\n",
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    return image\n",
    "\n",
    "# 分类图像\n",
    "def classify_image(image_path):\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            image = preprocess_image(image_path)\n",
    "            outputs = model(image)\n",
    "            _, predicted = outputs.max(1)\n",
    "            print(f\"Image {os.path.basename(image_path)} - Predicted Class: {predicted.item()}\")\n",
    "            torch.cuda.empty_cache()  # 每次推理后清理显存\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "# 扫描指定目录中的所有 JPG 图像\n",
    "def classify_images_in_directory(directory_path):\n",
    "    if not os.path.exists(directory_path):\n",
    "        print(\"Directory not found.\")\n",
    "        return\n",
    "    \n",
    "    image_files = [f for f in os.listdir(directory_path) if f.lower().endswith('.jpg')]\n",
    "    if not image_files:\n",
    "        print(\"No JPG images found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(image_files)} images.\")\n",
    "    for img_file in image_files:\n",
    "        classify_image(os.path.join(directory_path, img_file))\n",
    "\n",
    "# 运行分类\n",
    "directory_path = r\"D:/Desktop/5243Bianca/Final Project/middle_section\"\n",
    "classify_images_in_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM(Segment Anything Model) zero shot -> lizard mask -google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 70/70 [00:53<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! Extracted lizards saved to D:/Desktop/5243Bianca/Final Project/extracted_lizards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_lizard(original_img_path, mask_img_path, output_path):\n",
    "    \"\"\"\n",
    "    Extract lizard from original image using the mask and save with transparent background\n",
    "    \n",
    "    Args:\n",
    "        original_img_path: Path to the original JPG image\n",
    "        mask_img_path: Path to the binary mask PNG image\n",
    "        output_path: Path to save the extracted lizard with transparent background\n",
    "    \"\"\"\n",
    "    # Read the original image and mask\n",
    "    original = cv2.imread(original_img_path)\n",
    "    mask = cv2.imread(mask_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Check if images were loaded properly\n",
    "    if original is None:\n",
    "        print(f\"Error: Could not load original image {original_img_path}\")\n",
    "        return\n",
    "    if mask is None:\n",
    "        print(f\"Error: Could not load mask image {mask_img_path}\")\n",
    "        return\n",
    "    \n",
    "    # Resize mask if dimensions don't match\n",
    "    if original.shape[:2] != mask.shape[:2]:\n",
    "        mask = cv2.resize(mask, (original.shape[1], original.shape[0]))\n",
    "    \n",
    "    # Create an alpha channel (transparency) from the mask\n",
    "    # Convert to binary mask if not already (values 0 or 255)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Convert BGR to BGRA (add alpha channel)\n",
    "    rgba = cv2.cvtColor(original, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    # Set alpha channel based on mask (255 for lizard, 0 for background)\n",
    "    rgba[:, :, 3] = binary_mask\n",
    "    \n",
    "    # Save the result with transparency\n",
    "    cv2.imwrite(output_path, rgba)\n",
    "    \n",
    "def process_all_images(original_dir, mask_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all images in the directories\n",
    "    \n",
    "    Args:\n",
    "        original_dir: Directory containing original JPG images\n",
    "        mask_dir: Directory containing mask PNG images\n",
    "        output_dir: Directory to save output images\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of mask files\n",
    "    mask_files = [f for f in os.listdir(mask_dir) if f.endswith('_mask.png')]\n",
    "    \n",
    "    for mask_file in tqdm(mask_files, desc=\"Processing images\"):\n",
    "        # Extract base name from mask (remove _mask.png)\n",
    "        base_name = mask_file.replace('_raw_mask.png', '')\n",
    "        \n",
    "        # Find corresponding original file\n",
    "        original_file = f\"{base_name}.JPG\"\n",
    "        \n",
    "        # Build full paths\n",
    "        original_path = os.path.join(original_dir, original_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_extracted.png\")\n",
    "        \n",
    "        # Check if original file exists\n",
    "        if os.path.exists(original_path):\n",
    "            extract_lizard(original_path, mask_path, output_path)\n",
    "        else:\n",
    "            # Try with lowercase extension\n",
    "            original_file = f\"{base_name}.jpg\"\n",
    "            original_path = os.path.join(original_dir, original_file)\n",
    "            if os.path.exists(original_path):\n",
    "                extract_lizard(original_path, mask_path, output_path)\n",
    "            else:\n",
    "                print(f\"Warning: Could not find original image for mask {mask_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory paths - update these according to your file structure\n",
    "    original_dir = \"D:/Desktop/5243Bianca/Final Project/Dorsal/Dorsal\"  # Where the original JPG files are located\n",
    "    mask_dir = \"D:/Desktop/5243Bianca/Final Project/dorsal_mask\"  # Where the mask PNG files are located\n",
    "    output_dir = \"D:/Desktop/5243Bianca/Final Project/extracted_lizards\"  # Where to save the extracted lizards\n",
    "    \n",
    "    process_all_images(original_dir, mask_dir, output_dir)\n",
    "    print(f\"Finished! Extracted lizards saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D:\\Desktop\\5243Bianca\\Final Project\\extracted_lizards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "增强图像: 100%|██████████| 66/66 [07:56<00:00,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据增强完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = \"D:/Desktop/5243Bianca/Final Project/extracted_lizards\"\n",
    "output_dir = \"D:/Desktop/5243Bianca/Final Project/augmented_lizards\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def augment_transparent_image(image_path, output_dir, num_augmentations=10):\n",
    "\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        print(f\"无法读取图像: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    filename = os.path.basename(image_path)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    rgb = img[:,:,:3]\n",
    "    alpha = img[:,:,3] if img.shape[2] == 4 else np.ones(img.shape[:2], dtype=np.uint8) * 255\n",
    "    \n",
    "    max_rotation = 20\n",
    "    max_shift = 0.2\n",
    "    max_zoom = 0.2\n",
    "    \n",
    "    for i in range(num_augmentations):\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        angle = np.random.uniform(-max_rotation, max_rotation)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "        \n",
    "        tx = np.random.uniform(-max_shift, max_shift) * w\n",
    "        ty = np.random.uniform(-max_shift, max_shift) * h\n",
    "        rotation_matrix[0, 2] += tx\n",
    "        rotation_matrix[1, 2] += ty\n",
    "\n",
    "        scale = np.random.uniform(1-max_zoom, 1+max_zoom)\n",
    "        scaled_w, scaled_h = int(w * scale), int(h * scale)\n",
    "        \n",
    "        rgb_transformed = cv2.warpAffine(\n",
    "            rgb, rotation_matrix, (w, h), \n",
    "            flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0)\n",
    "        )\n",
    "        \n",
    "        alpha_transformed = cv2.warpAffine(\n",
    "            alpha, rotation_matrix, (w, h), \n",
    "            flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0\n",
    "        )\n",
    "        \n",
    "        if np.random.random() > 0.5:\n",
    "            rgb_transformed = cv2.flip(rgb_transformed, 1)\n",
    "            alpha_transformed = cv2.flip(alpha_transformed, 1)\n",
    "\n",
    "        augmented_img = np.zeros((h, w, 4), dtype=np.uint8)\n",
    "        augmented_img[:,:,:3] = rgb_transformed\n",
    "        augmented_img[:,:,3] = alpha_transformed\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_aug_{i}.png\")\n",
    "        cv2.imwrite(output_path, augmented_img)\n",
    "\n",
    "image_files = [f for f in os.listdir(input_dir) if f.endswith('.png')]\n",
    "\n",
    "for filename in tqdm(image_files, desc=\"增强图像\"):\n",
    "    image_path = os.path.join(input_dir, filename)\n",
    "    augment_transparent_image(image_path, output_dir)\n",
    "\n",
    "print(\"数据增强完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction，t-SNE,RF\n",
    "\n",
    "## augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "映射表中的文件名（去除扩展名）如下：\n",
      "['P1010185', 'P1010187', 'P1010189', 'P1010191', 'P1010193', 'P1010195', 'P1010197', 'P1010199', 'P1010201', 'P1010203', 'P1010205', 'P1010207', 'P1010209', 'P1010211', 'P1010330', 'P1010333', 'P1010336', 'P1010338', 'P1010340', 'P1010343', 'P1010346', 'P1010348', 'P1010350', 'P1010352', 'P1010355', 'P1010357', 'P1010360', 'IMG_1411', 'IMG_1414', 'IMG_1417', 'IMG_1419', 'IMG_1421', 'IMG_1423', 'IMG_1425', 'IMG_1427', 'IMG_1429', 'IMG_1432', 'IMG_1434', 'IMG_1436', 'IMG_1438', 'IMG_1440', 'IMG_1443', 'IMG_1446', 'IMG_1448', 'YQ1401-D', 'YQ1402-D', 'YQ1403-D', 'YQ1404-D', 'YQ1405-D', 'YQ1406-D', 'YQ1407-D', 'YQ1408-D', 'YQ1409-D', 'YQ1410-D', 'YQ1411-D', 'YQ1412-D', 'YQ1413-D', 'YQ1414-D', 'YQ1415-D', 'YQ1416-D', 'YQ1417-D', 'IMG_1451', 'IMG_1453', 'IMG_1455', 'IMG_1457', 'IMG_1459', 'IMG_1461', 'IMG_1463', 'IMG_1465', 'IMG_1468']\n",
      "Loaded class mapping for 70 files across 4 lizard classes.\n",
      "Extracting features using mobilenetv2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mobilenetv2 feature extraction: 100%|██████████| 660/660 [04:57<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features using mobilenetv3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mobilenetv3 feature extraction: 100%|██████████| 660/660 [04:42<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running t-SNE visualization for mobilenetv2 features...\n",
      "Selecting top 20 features from mobilenetv2...\n",
      "Running t-SNE visualization for mobilenetv3 features...\n",
      "Selecting top 20 features from mobilenetv3...\n",
      "特征提取、可视化与选择完成！\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Small\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "# Set paths\n",
    "augmented_dir = \"D:/Desktop/5243Bianca/Final Project/augmented_lizards\"\n",
    "original_dir = \"D:/Desktop/5243Bianca/Final Project/extracted_lizards\"\n",
    "features_output_dir = \"D:/Desktop/5243Bianca/Final Project/lizard_features\"\n",
    "visualization_dir = \"D:/Desktop/5243Bianca/Final Project/visualizations\"\n",
    "class_mapping_file = \"D:/Desktop/5243Bianca/Final Project/filename_class.xlsx\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [features_output_dir, visualization_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Load the class mapping file\n",
    "def load_class_mapping():\n",
    "    try:\n",
    "        # 指定 header=0 表示第一行是列名（类名）\n",
    "        mapping_df = pd.read_excel(class_mapping_file, header=0)\n",
    "        class_names = mapping_df.columns.tolist()\n",
    "        \n",
    "        filename_to_class = {}\n",
    "        \n",
    "        for class_name in class_names:\n",
    "            filenames = mapping_df[class_name].dropna().tolist()\n",
    "            for filename in filenames:\n",
    "                # 去掉空格和扩展名（如 .JPG）\n",
    "                filename_clean = os.path.splitext(str(filename).strip())[0].strip()\n",
    "                filename_to_class[filename_clean] = class_name\n",
    "        \n",
    "        return filename_to_class, class_names\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading class mapping file: {e}\")\n",
    "        return {}, []\n",
    "\n",
    "\n",
    "# Function to load and preprocess an image for MobileNet models\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    # Load image with PIL to properly handle transparency\n",
    "    img = Image.open(image_path).convert('RGBA')\n",
    "    \n",
    "    # Create a white background image\n",
    "    background = Image.new('RGBA', img.size, (255, 255, 255, 255))\n",
    "    \n",
    "    # Alpha composite the image with the white background\n",
    "    img = Image.alpha_composite(background, img)\n",
    "    \n",
    "    # Convert to RGB (remove alpha channel)\n",
    "    img = img.convert('RGB')\n",
    "    \n",
    "    # Resize image\n",
    "    img = img.resize(target_size)\n",
    "    \n",
    "    # Convert to array and preprocess\n",
    "    img_array = img_to_array(img)\n",
    "    \n",
    "    # Scale pixel values to [0,1]\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "# Create feature extractors based on pretrained models\n",
    "def create_feature_extractors():\n",
    "    # MobileNetV2\n",
    "    base_model_v2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model_v2.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    model_v2 = Model(inputs=base_model_v2.input, outputs=x)\n",
    "    \n",
    "    # Freeze all layers in the base model\n",
    "    for layer in base_model_v2.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # MobileNetV3Small\n",
    "    base_model_v3 = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model_v3.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    model_v3 = Model(inputs=base_model_v3.input, outputs=x)\n",
    "    \n",
    "    # Freeze all layers in the base model\n",
    "    for layer in base_model_v3.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return {\n",
    "        'mobilenetv2': model_v2,\n",
    "        'mobilenetv3': model_v3,\n",
    "    }\n",
    "\n",
    "import re\n",
    "\n",
    "def get_original_filename(filename):\n",
    "    \"\"\"\n",
    "    提取增强图像对应的原始文件名\n",
    "    例子：\n",
    "        IMG_1411_extracted_aug_0.png -> IMG_1411\n",
    "        P1010185_extracted_aug_3.png -> P1010185\n",
    "    \"\"\"\n",
    "    match = re.match(r\"^(.*?)(?:_extracted)?(?:_aug_\\d+)?\\.png$\", filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Extract features from images\n",
    "def extract_features(image_dir, feature_extractors, filename_to_class):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Collect all image paths and extract labels from filenames\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.png'):\n",
    "            # Extract the original filename (before augmentation)\n",
    "            # Format is \"种群名_extracted_aug_数字.png\"\n",
    "            # 提取原始文件名\n",
    "            original_name = get_original_filename(filename)\n",
    "\n",
    "            # 匹配 class\n",
    "            class_name = filename_to_class.get(original_name)\n",
    "            if class_name:\n",
    "                image_paths.append(os.path.join(image_dir, filename))\n",
    "                labels.append(class_name)\n",
    "            else:\n",
    "                print(f\"Warning: Could not determine class for {filename}\")\n",
    "    \n",
    "    features = {}\n",
    "    for model_name, model in feature_extractors.items():\n",
    "        print(f\"Extracting features using {model_name}...\")\n",
    "        model_features = []\n",
    "        \n",
    "        for img_path in tqdm(image_paths, desc=f\"{model_name} feature extraction\"):\n",
    "            try:\n",
    "                img_array = load_and_preprocess_image(img_path)\n",
    "                img_array = np.expand_dims(img_array, axis=0)\n",
    "                features_vector = model.predict(img_array, verbose=0)\n",
    "                model_features.append(features_vector.flatten())\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "                # Add a placeholder of zeros to maintain index alignment\n",
    "                model_features.append(np.zeros(model.output_shape[1:]))\n",
    "        \n",
    "        features[model_name] = np.array(model_features)\n",
    "    \n",
    "    return features, labels, image_paths\n",
    "\n",
    "# Visualize features using t-SNE\n",
    "def visualize_features_tsne(features, labels, model_name, class_names):\n",
    "    print(f\"Running t-SNE visualization for {model_name} features...\")\n",
    "    \n",
    "    # Convert labels to numerical format for coloring\n",
    "    label_to_id = {label: i for i, label in enumerate(class_names)}\n",
    "    numeric_labels = [label_to_id[label] for label in labels]\n",
    "    \n",
    "    # Apply t-SNE for dimensionality reduction\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(labels)-1))\n",
    "    features_2d = tsne.fit_transform(features)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=numeric_labels, cmap='viridis', alpha=0.7)\n",
    "    \n",
    "    # Add legend\n",
    "    legend1 = plt.legend(scatter.legend_elements()[0], class_names, title=\"Lizard Types\", loc=\"upper right\")\n",
    "    plt.gca().add_artist(legend1)\n",
    "    \n",
    "    plt.title(f't-SNE visualization of {model_name} features')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(visualization_dir, f'{model_name}_tsne.png'), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Use Random Forest to select important features\n",
    "def select_features(features, labels, model_name, class_names, n_features=20):\n",
    "    print(f\"Selecting top {n_features} features from {model_name}...\")\n",
    "    \n",
    "    # Convert labels to numerical\n",
    "    label_to_id = {label: i for i, label in enumerate(class_names)}\n",
    "    numeric_labels = np.array([label_to_id[label] for label in labels])\n",
    "    \n",
    "    # Train a Random Forest classifier to get feature importance\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(features, numeric_labels)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importances = rf.feature_importances_\n",
    "    \n",
    "    # Create indices of top n features\n",
    "    indices = np.argsort(importances)[::-1][:n_features]\n",
    "    top_importances = importances[indices]\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f'Top {n_features} Feature Importances - {model_name}')\n",
    "    plt.bar(range(n_features), top_importances)\n",
    "    plt.xticks(range(n_features), indices, rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(visualization_dir, f'{model_name}_feature_importance.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Return selected features and their indices\n",
    "    return features[:, indices], indices, top_importances\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Load class mapping from Excel\n",
    "    filename_to_class, class_names = load_class_mapping()\n",
    "    print(\"映射表中的文件名（去除扩展名）如下：\")\n",
    "    print(list(filename_to_class.keys()))\n",
    "\n",
    "    print(f\"Loaded class mapping for {len(filename_to_class)} files across {len(class_names)} lizard classes.\")\n",
    "    \n",
    "    # Create feature extractors\n",
    "    feature_extractors = create_feature_extractors()\n",
    "    \n",
    "    # Extract features from augmented images\n",
    "    features, labels, image_paths = extract_features(augmented_dir, feature_extractors, filename_to_class)\n",
    "    \n",
    "    # Save the mapping of images to labels\n",
    "    image_labels_df = pd.DataFrame({\n",
    "        'image_path': image_paths,\n",
    "        'class': labels\n",
    "    })\n",
    "    image_labels_df.to_csv(os.path.join(features_output_dir, 'image_labels.csv'), index=False)\n",
    "    \n",
    "    # Process each model's features\n",
    "    for model_name, model_features in features.items():\n",
    "        # Save raw features\n",
    "        np.save(os.path.join(features_output_dir, f'{model_name}_features.npy'), model_features)\n",
    "        np.save(os.path.join(features_output_dir, f'labels.npy'), np.array(labels))\n",
    "        \n",
    "        # Visualize with t-SNE\n",
    "        visualize_features_tsne(model_features, labels, model_name, class_names)\n",
    "        \n",
    "        # Select top features\n",
    "        selected_features, top_indices, top_importances = select_features(model_features, labels, model_name, class_names)\n",
    "        \n",
    "        # Save selected features\n",
    "        np.save(os.path.join(features_output_dir, f'{model_name}_selected_features.npy'), selected_features)\n",
    "        np.save(os.path.join(features_output_dir, f'{model_name}_top_indices.npy'), top_indices)\n",
    "        \n",
    "        # Create a DataFrame with feature importance info\n",
    "        feature_info = pd.DataFrame({\n",
    "            'feature_index': top_indices,\n",
    "            'importance': top_importances\n",
    "        })\n",
    "        feature_info.to_csv(os.path.join(features_output_dir, f'{model_name}_feature_importance.csv'), index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"特征提取、可视化与选择完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating mobilenetv2 - Selected Features\n",
      "Training and evaluating Linear SVM...\n",
      "Training and evaluating RBF SVM...\n",
      "Training and evaluating Random Forest...\n",
      "Training and evaluating AdaBoost...\n",
      "Training and evaluating KNN...\n",
      "Training and evaluating Naive Bayes...\n",
      "\n",
      "Evaluating mobilenetv2 - All Features\n",
      "Training and evaluating Linear SVM...\n",
      "Training and evaluating RBF SVM...\n",
      "Training and evaluating Random Forest...\n",
      "Training and evaluating AdaBoost...\n",
      "Training and evaluating KNN...\n",
      "Training and evaluating Naive Bayes...\n",
      "\n",
      "Evaluating mobilenetv3 - Selected Features\n",
      "Training and evaluating Linear SVM...\n",
      "Training and evaluating RBF SVM...\n",
      "Training and evaluating Random Forest...\n",
      "Training and evaluating AdaBoost...\n",
      "Training and evaluating KNN...\n",
      "Training and evaluating Naive Bayes...\n",
      "\n",
      "Evaluating mobilenetv3 - All Features\n",
      "Training and evaluating Linear SVM...\n",
      "Training and evaluating RBF SVM...\n",
      "Training and evaluating Random Forest...\n",
      "Training and evaluating AdaBoost...\n",
      "Training and evaluating KNN...\n",
      "Training and evaluating Naive Bayes...\n",
      "\n",
      "Best configuration:\n",
      "Model: mobilenetv2\n",
      "Feature Type: All\n",
      "Classifier: Linear SVM\n",
      "Accuracy: 0.9924\n",
      "F1-Score: 0.9924\n",
      "\n",
      "Performing Bayesian optimization for Linear SVM...\n",
      "Best parameters: OrderedDict([('C', 0.661009829541915), ('tol', 0.0015246748254295628)])\n",
      "Best cross-validation score: 0.8591\n",
      "\n",
      "Final evaluation of optimized Linear SVM:\n",
      "Average Accuracy: 0.9909\n",
      "Average F1-Score: 0.9909\n",
      "\n",
      "Classification and optimization completed successfully!\n",
      "All results saved to: D:/Desktop/5243Bianca/Final Project/classification_results\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "# Set paths\n",
    "features_output_dir = \"D:/Desktop/5243Bianca/Final Project/lizard_features\"\n",
    "results_dir = \"D:/Desktop/5243Bianca/Final Project/classification_results\"\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "def load_features(model_name, use_selected=True):\n",
    "    \"\"\"\n",
    "    Load features extracted from the specified model\n",
    "    \n",
    "    Args:\n",
    "        model_name: 'mobilenetv2' or 'mobilenetv3'\n",
    "        use_selected: Whether to use the pre-selected top features\n",
    "    \n",
    "    Returns:\n",
    "        features: Feature matrix\n",
    "        labels: Class labels\n",
    "    \"\"\"\n",
    "    # Load labels\n",
    "    labels = np.load(os.path.join(features_output_dir, 'labels.npy'), allow_pickle=True)\n",
    "    \n",
    "    # Load features\n",
    "    if use_selected:\n",
    "        features = np.load(os.path.join(features_output_dir, f'{model_name}_selected_features.npy'))\n",
    "    else:\n",
    "        features = np.load(os.path.join(features_output_dir, f'{model_name}_features.npy'))\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def encode_labels(labels):\n",
    "    \"\"\"Convert string labels to numerical values\"\"\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    return label_encoder.fit_transform(labels), label_encoder\n",
    "\n",
    "def train_and_evaluate_classifiers(features, labels):\n",
    "    \"\"\"\n",
    "    Train and evaluate multiple classifiers using 4-fold cross-validation\n",
    "    \n",
    "    Args:\n",
    "        features: Feature matrix\n",
    "        labels: Numerical class labels\n",
    "        \n",
    "    Returns:\n",
    "        results_df: DataFrame with performance metrics for each classifier\n",
    "    \"\"\"\n",
    "    # Define classifiers to test\n",
    "    classifiers = {\n",
    "        'Linear SVM': SVC(kernel='linear', random_state=42),\n",
    "        'RBF SVM': SVC(kernel='rbf', random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(random_state=42),\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'Naive Bayes': GaussianNB()\n",
    "    }\n",
    "    \n",
    "    # Initialize results storage\n",
    "    results = []\n",
    "    \n",
    "    # Initialize K-fold cross-validation\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    for clf_name, clf in classifiers.items():\n",
    "        print(f\"Training and evaluating {clf_name}...\")\n",
    "        \n",
    "        fold_accuracies = []\n",
    "        fold_f1_scores = []\n",
    "        fold = 1\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        for train_idx, test_idx in kf.split(features):\n",
    "            X_train, X_test = features[train_idx], features[test_idx]\n",
    "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "            \n",
    "            # Scale features\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "            \n",
    "            # Train classifier\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = clf.predict(X_test)\n",
    "            \n",
    "            # Compute metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            fold_accuracies.append(accuracy)\n",
    "            fold_f1_scores.append(f1)\n",
    "            \n",
    "            # Record individual fold results\n",
    "            results.append({\n",
    "                'Classifier': clf_name,\n",
    "                'Fold': fold,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1-Score': f1\n",
    "            })\n",
    "            \n",
    "            fold += 1\n",
    "        \n",
    "        # Record average results\n",
    "        results.append({\n",
    "            'Classifier': clf_name,\n",
    "            'Fold': 'Average',\n",
    "            'Accuracy': np.mean(fold_accuracies),\n",
    "            'F1-Score': np.mean(fold_f1_scores)\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def plot_classifier_performance(results_df):\n",
    "    \"\"\"Plot the performance of different classifiers\"\"\"\n",
    "    # Extract average performances\n",
    "    avg_results = results_df[results_df['Fold'] == 'Average'].copy()\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    sns.barplot(x='Classifier', y='Accuracy', data=avg_results, ax=ax1)\n",
    "    ax1.set_title('Average Accuracy Across 4-Fold CV')\n",
    "    ax1.set_ylim(0, 1)  # Set y-axis from 0 to 1\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Plot F1-Score\n",
    "    sns.barplot(x='Classifier', y='F1-Score', data=avg_results, ax=ax2)\n",
    "    ax2.set_title('Average F1-Score Across 4-Fold CV')\n",
    "    ax2.set_ylim(0, 1)  # Set y-axis from 0 to 1\n",
    "    ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'classifier_performance.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def optimize_best_classifier(features, labels, best_classifier):\n",
    "    \"\"\"\n",
    "    Perform Bayesian optimization for the best classifier\n",
    "    \n",
    "    Args:\n",
    "        features: Feature matrix\n",
    "        labels: Numerical class labels\n",
    "        best_classifier: Name of the best classifier\n",
    "        \n",
    "    Returns:\n",
    "        best_params: Best parameters found\n",
    "        best_score: Best score achieved\n",
    "    \"\"\"\n",
    "    # Scale features\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    \n",
    "    # Define search spaces for different classifiers\n",
    "    if best_classifier == 'Linear SVM':\n",
    "        model = SVC(kernel='linear', random_state=42)\n",
    "        param_space = {\n",
    "            'C': Real(0.1, 10.0, prior='log-uniform'),\n",
    "            'tol': Real(1e-5, 1e-2, prior='log-uniform')\n",
    "        }\n",
    "    elif best_classifier == 'RBF SVM':\n",
    "        model = SVC(kernel='rbf', random_state=42)\n",
    "        param_space = {\n",
    "            'C': Real(0.1, 10.0, prior='log-uniform'),\n",
    "            'gamma': Real(0.001, 1.0, prior='log-uniform'),\n",
    "            'tol': Real(1e-5, 1e-2, prior='log-uniform')\n",
    "        }\n",
    "    elif best_classifier == 'Random Forest':\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "        param_space = {\n",
    "            'n_estimators': Integer(50, 300),\n",
    "            'max_depth': Integer(3, 20),\n",
    "            'min_samples_split': Integer(2, 10),\n",
    "            'min_samples_leaf': Integer(1, 5)\n",
    "        }\n",
    "    elif best_classifier == 'AdaBoost':\n",
    "        model = AdaBoostClassifier(random_state=42)\n",
    "        param_space = {\n",
    "            'n_estimators': Integer(50, 300),\n",
    "            'learning_rate': Real(0.01, 1.0, prior='log-uniform')\n",
    "        }\n",
    "    elif best_classifier == 'KNN':\n",
    "        model = KNeighborsClassifier()\n",
    "        param_space = {\n",
    "            'n_neighbors': Integer(3, 15),\n",
    "            'weights': Categorical(['uniform', 'distance']),\n",
    "            'p': Integer(1, 2)\n",
    "        }\n",
    "    else:  # Naive Bayes\n",
    "        model = GaussianNB()\n",
    "        param_space = {\n",
    "            'var_smoothing': Real(1e-10, 1e-8, prior='log-uniform')\n",
    "        }\n",
    "    \n",
    "    # Define Bayesian search\n",
    "    opt = BayesSearchCV(\n",
    "        model,\n",
    "        param_space,\n",
    "        n_iter=30,  # Number of parameter settings that are sampled\n",
    "        cv=4,        # 4-fold cross-validation\n",
    "        n_jobs=-1,   # Use all available CPUs\n",
    "        random_state=42,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    # Perform optimization\n",
    "    print(f\"\\nPerforming Bayesian optimization for {best_classifier}...\")\n",
    "    opt.fit(scaled_features, labels)\n",
    "    \n",
    "    # Get results\n",
    "    print(f\"Best parameters: {opt.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {opt.best_score_:.4f}\")\n",
    "    \n",
    "    # Train the model with best params on the full dataset\n",
    "    best_model = opt.best_estimator_\n",
    "    \n",
    "    # Save optimization results\n",
    "    optimization_results = {\n",
    "        'best_params': opt.best_params_,\n",
    "        'best_score': opt.best_score_,\n",
    "        'all_scores': opt.cv_results_\n",
    "    }\n",
    "    \n",
    "    # Evaluate the optimized model with cross-validation\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    fold_accuracies = []\n",
    "    fold_f1_scores = []\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(scaled_features):\n",
    "        X_train, X_test = scaled_features[train_idx], scaled_features[test_idx]\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "        \n",
    "        # Train with optimal parameters\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Collect results\n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        \n",
    "        # Metrics for this fold\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        fold_accuracies.append(accuracy)\n",
    "        fold_f1_scores.append(f1)\n",
    "    \n",
    "    # Final metrics\n",
    "    final_accuracy = np.mean(fold_accuracies)\n",
    "    final_f1 = np.mean(fold_f1_scores)\n",
    "    \n",
    "    # Create and plot confusion matrix\n",
    "    cm = confusion_matrix(all_y_true, all_y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - Optimized {best_classifier}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, f'confusion_matrix_{best_classifier.lower().replace(\" \", \"_\")}.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(all_y_true, all_y_pred, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(os.path.join(results_dir, f'classification_report_{best_classifier.lower().replace(\" \", \"_\")}.csv'))\n",
    "    \n",
    "    print(f\"\\nFinal evaluation of optimized {best_classifier}:\")\n",
    "    print(f\"Average Accuracy: {final_accuracy:.4f}\")\n",
    "    print(f\"Average F1-Score: {final_f1:.4f}\")\n",
    "    \n",
    "    return optimization_results\n",
    "\n",
    "def compare_models_and_features():\n",
    "    \"\"\"Compare performance between MobileNetV2 and MobileNetV3 features\"\"\"\n",
    "    models = ['mobilenetv2', 'mobilenetv3']\n",
    "    feature_types = [True, False]  # True for selected features, False for all features\n",
    "    \n",
    "    all_results_list = []\n",
    "    \n",
    "    for model_name in models:\n",
    "        for use_selected in feature_types:\n",
    "            feature_type = \"Selected\" if use_selected else \"All\"\n",
    "            print(f\"\\nEvaluating {model_name} - {feature_type} Features\")\n",
    "            \n",
    "            # Load features and labels\n",
    "            features, labels = load_features(model_name, use_selected)\n",
    "            encoded_labels, _ = encode_labels(labels)\n",
    "            \n",
    "            # Train and evaluate\n",
    "            model_results = train_and_evaluate_classifiers(features, encoded_labels)\n",
    "            \n",
    "            # Add model and feature type information\n",
    "            model_results['Model'] = model_name\n",
    "            model_results['Feature Type'] = feature_type\n",
    "            \n",
    "            # Append to overall results\n",
    "            all_results_list.append(model_results)\n",
    "    \n",
    "    # Combine all results\n",
    "    all_results = pd.concat(all_results_list)\n",
    "    all_results.to_csv(os.path.join(results_dir, 'all_classification_results.csv'), index=False)\n",
    "    \n",
    "    # Plot comparison of average performances\n",
    "    avg_results = all_results[all_results['Fold'] == 'Average'].copy()\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot accuracy comparison\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.barplot(x='Classifier', y='Accuracy', hue='Model', data=avg_results)\n",
    "    plt.title('Average Accuracy Comparison')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(title='Model')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Plot F1-score comparison\n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.barplot(x='Classifier', y='F1-Score', hue='Model', data=avg_results)\n",
    "    plt.title('Average F1-Score Comparison')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(title='Model')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'model_comparison.png'), dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Find the best performing configuration - using numpy methods for reliability\n",
    "    best_accuracy_idx = avg_results['Accuracy'].values.argmax()\n",
    "    best_row = avg_results.iloc[best_accuracy_idx]\n",
    "    \n",
    "    # Create a dictionary to hold the best configuration\n",
    "    best_config = {\n",
    "        'Model': best_row['Model'],\n",
    "        'Feature Type': best_row['Feature Type'],\n",
    "        'Classifier': best_row['Classifier'],\n",
    "        'Accuracy': best_row['Accuracy'],\n",
    "        'F1-Score': best_row['F1-Score']\n",
    "    }\n",
    "    \n",
    "    print(\"\\nBest configuration:\")\n",
    "    print(f\"Model: {best_config['Model']}\")\n",
    "    print(f\"Feature Type: {best_config['Feature Type']}\")\n",
    "    print(f\"Classifier: {best_config['Classifier']}\")\n",
    "    print(f\"Accuracy: {best_config['Accuracy']:.4f}\")\n",
    "    print(f\"F1-Score: {best_config['F1-Score']:.4f}\")\n",
    "    \n",
    "    return best_config, all_results\n",
    "\n",
    "def main():\n",
    "    # Compare different models and feature types\n",
    "    best_config, all_results = compare_models_and_features()\n",
    "    \n",
    "    # Get the best model, feature type, and classifier\n",
    "    best_model = best_config['Model']\n",
    "    best_feature_type = best_config['Feature Type'] == 'Selected'\n",
    "    best_classifier = best_config['Classifier']\n",
    "    \n",
    "    # Load the best features\n",
    "    features, labels = load_features(best_model, best_feature_type)\n",
    "    encoded_labels, label_encoder = encode_labels(labels)\n",
    "    \n",
    "    # Optimize the best classifier\n",
    "    optimization_results = optimize_best_classifier(features, encoded_labels, best_classifier)\n",
    "    \n",
    "    # Save results\n",
    "    summary = {\n",
    "        'best_model': best_model,\n",
    "        'best_feature_type': 'Selected' if best_feature_type else 'All',\n",
    "        'best_classifier': best_classifier,\n",
    "        'original_accuracy': best_config['Accuracy'],\n",
    "        'original_f1': best_config['F1-Score'],\n",
    "        'optimized_accuracy': optimization_results['best_score'],\n",
    "        'optimized_params': optimization_results['best_params']\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(results_dir, 'optimization_summary.txt'), 'w') as f:\n",
    "        for key, value in summary.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    \n",
    "    print(\"\\nClassification and optimization completed successfully!\")\n",
    "    print(f\"All results saved to: {results_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像分类完成，所有文件已重新整理到 training_images/ 中。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "train_dir = \"D:/Desktop/5243Bianca/Final Project/augmented_lizards\"\n",
    "excel_path = \"D:/Desktop/5243Bianca/Final Project/filename_class.xlsx\"\n",
    "output_dir = \"D:/Desktop/5243Bianca/Final Project/training_images\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "df = pd.read_excel(excel_path, header=0)\n",
    "\n",
    "\n",
    "for class_name in df.columns:\n",
    "\n",
    "    prefix_list = df[class_name].dropna().astype(str).tolist()\n",
    "    \n",
    "\n",
    "    class_dir = os.path.join(output_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    for prefix in prefix_list:\n",
    "        for filename in os.listdir(train_dir):\n",
    "            if filename.startswith(prefix):\n",
    "                src_path = os.path.join(train_dir, filename)\n",
    "                dst_path = os.path.join(class_dir, filename)\n",
    "                \n",
    "                # 拷贝文件\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "\n",
    "print(\"图像分类完成，所有文件已重新整理到 training_images/ 中。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from training images...\n",
      "Training SVM classifier...\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "class LizardClassifier:\n",
    "    def __init__(self, model_dir=None):\n",
    "        \"\"\"\n",
    "        Initialize the lizard classifier pipeline with the best configuration.\n",
    "        \n",
    "        Args:\n",
    "            model_dir: Directory containing saved model files (optional)\n",
    "        \"\"\"\n",
    "        self.model_name = 'mobilenetv2'\n",
    "        self.use_all_features = True  # Using all features instead of selected\n",
    "        self.classifier_name = 'Linear SVM'\n",
    "        \n",
    "        # Create feature extractor (MobileNetV2)\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        self.feature_extractor = Model(inputs=base_model.input, outputs=x)\n",
    "        \n",
    "        # Freeze all layers in the base model\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        # Initialize classifier with optimized parameters\n",
    "        self.classifier = SVC(\n",
    "            kernel='linear',\n",
    "            C=0.661009829541915,\n",
    "            tol=0.0015246748254295628,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Initialize scaler for feature normalization\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "        # Initialize label encoder\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        \n",
    "        # Load pre-trained components if model_dir is provided\n",
    "        if model_dir:\n",
    "            self.load_model(model_dir)\n",
    "    \n",
    "    def load_model(self, model_dir):\n",
    "        \"\"\"\n",
    "        Load the pre-trained classifier and preprocessing components.\n",
    "        \n",
    "        Args:\n",
    "            model_dir: Directory containing saved model files\n",
    "        \"\"\"\n",
    "        # Load classifier\n",
    "        self.classifier = joblib.load(os.path.join(model_dir, 'svm_classifier.joblib'))\n",
    "        \n",
    "        # Load scaler\n",
    "        self.scaler = joblib.load(os.path.join(model_dir, 'feature_scaler.joblib'))\n",
    "        \n",
    "        # Load label encoder\n",
    "        with open(os.path.join(model_dir, 'label_encoder.pkl'), 'rb') as f:\n",
    "            self.label_encoder = pickle.load(f)\n",
    "    \n",
    "    def save_model(self, model_dir):\n",
    "        \"\"\"\n",
    "        Save the trained classifier and preprocessing components.\n",
    "        \n",
    "        Args:\n",
    "            model_dir: Directory to save model files\n",
    "        \"\"\"\n",
    "        # Create directory if it doesn't exist\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        \n",
    "        # Save classifier\n",
    "        joblib.dump(self.classifier, os.path.join(model_dir, 'svm_classifier.joblib'))\n",
    "        \n",
    "        # Save scaler\n",
    "        joblib.dump(self.scaler, os.path.join(model_dir, 'feature_scaler.joblib'))\n",
    "        \n",
    "        # Save label encoder\n",
    "        with open(os.path.join(model_dir, 'label_encoder.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.label_encoder, f)\n",
    "    \n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"\n",
    "        Preprocess a single image for feature extraction.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            Preprocessed image array\n",
    "        \"\"\"\n",
    "        # Load image with PIL to properly handle transparency\n",
    "        img = Image.open(image_path).convert('RGBA')\n",
    "        \n",
    "        # Create a white background image\n",
    "        background = Image.new('RGBA', img.size, (255, 255, 255, 255))\n",
    "        \n",
    "        # Alpha composite the image with the white background\n",
    "        img = Image.alpha_composite(background, img)\n",
    "        \n",
    "        # Convert to RGB (remove alpha channel)\n",
    "        img = img.convert('RGB')\n",
    "        \n",
    "        # Resize image to match MobileNetV2 input size\n",
    "        img = img.resize((224, 224))\n",
    "        \n",
    "        # Convert to array and normalize\n",
    "        img_array = np.array(img).astype(np.float32)\n",
    "        img_array = img_array / 255.0\n",
    "        \n",
    "        return img_array\n",
    "    \n",
    "    def extract_features(self, image_array):\n",
    "        \"\"\"\n",
    "        Extract features from preprocessed image using MobileNetV2.\n",
    "        \n",
    "        Args:\n",
    "            image_array: Preprocessed image array\n",
    "            \n",
    "        Returns:\n",
    "            Feature vector\n",
    "        \"\"\"\n",
    "        # Add batch dimension\n",
    "        img_array = np.expand_dims(image_array, axis=0)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.feature_extractor.predict(img_array, verbose=0)\n",
    "        \n",
    "        return features.flatten()\n",
    "    \n",
    "    def fit(self, image_paths, labels):\n",
    "        \"\"\"\n",
    "        Train the classifier using a list of images and their labels.\n",
    "        \n",
    "        Args:\n",
    "            image_paths: List of paths to images\n",
    "            labels: List of class labels\n",
    "        \"\"\"\n",
    "        print(\"Extracting features from training images...\")\n",
    "        features = []\n",
    "        \n",
    "        # Extract features from all images\n",
    "        for img_path in image_paths:\n",
    "            img_array = self.preprocess_image(img_path)\n",
    "            features.append(self.extract_features(img_array))\n",
    "        \n",
    "        features = np.array(features)\n",
    "        \n",
    "        # Fit the label encoder\n",
    "        encoded_labels = self.label_encoder.fit_transform(labels)\n",
    "        \n",
    "        # Scale features\n",
    "        scaled_features = self.scaler.fit_transform(features)\n",
    "        \n",
    "        # Train the classifier\n",
    "        print(\"Training SVM classifier...\")\n",
    "        self.classifier.fit(scaled_features, encoded_labels)\n",
    "        \n",
    "        print(\"Training completed successfully!\")\n",
    "    \n",
    "    def predict(self, image_path):\n",
    "        \"\"\"\n",
    "        Predict the class of a single image.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            Predicted class label\n",
    "        \"\"\"\n",
    "        # Preprocess image\n",
    "        img_array = self.preprocess_image(image_path)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.extract_features(img_array)\n",
    "        \n",
    "        # Scale features\n",
    "        scaled_features = self.scaler.transform(features.reshape(1, -1))\n",
    "        \n",
    "        # Predict class\n",
    "        encoded_prediction = self.classifier.predict(scaled_features)[0]\n",
    "        \n",
    "        # Convert to original label\n",
    "        prediction = self.label_encoder.inverse_transform([encoded_prediction])[0]\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def predict_proba(self, image_path):\n",
    "        \"\"\"\n",
    "        Predict class probabilities for a single image.\n",
    "        \n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping class labels to probabilities\n",
    "        \"\"\"\n",
    "        # Preprocess image\n",
    "        img_array = self.preprocess_image(image_path)\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.extract_features(img_array)\n",
    "        \n",
    "        # Scale features\n",
    "        scaled_features = self.scaler.transform(features.reshape(1, -1))\n",
    "        \n",
    "        # Predict class probabilities\n",
    "        if hasattr(self.classifier, 'predict_proba'):\n",
    "            proba = self.classifier.predict_proba(scaled_features)[0]\n",
    "        else:\n",
    "            # For SVM, use decision_function and convert to probabilities\n",
    "            decision = self.classifier.decision_function(scaled_features)\n",
    "            proba = tf.nn.softmax(decision, axis=1).numpy()[0]\n",
    "        \n",
    "        # Create dictionary mapping class labels to probabilities\n",
    "        classes = self.label_encoder.classes_\n",
    "        class_proba = {classes[i]: proba[i] for i in range(len(classes))}\n",
    "        \n",
    "        return class_proba\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the pipeline\n",
    "    classifier = LizardClassifier()\n",
    "    \n",
    "    # Example paths for model training\n",
    "    images_dir = \"D:/Desktop/5243Bianca/Final Project/training_images\"\n",
    "    model_save_dir = \"D:/Desktop/5243Bianca/Final Project/save_model\"\n",
    "    \n",
    "    # Example training code (commented out)\n",
    "    \n",
    "    # Load training data\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Assuming folder structure with class names as subdirectories\n",
    "    for class_name in os.listdir(images_dir):\n",
    "        class_dir = os.path.join(images_dir, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "                    img_path = os.path.join(class_dir, filename)\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(class_name)\n",
    "    \n",
    "    # Train the classifier\n",
    "    classifier.fit(image_paths, labels)\n",
    "    \n",
    "    # Save the trained model\n",
    "    classifier.save_model(model_save_dir)\n",
    "\n",
    "    \n",
    "    # # Example prediction code\n",
    "\n",
    "    # # Load a pre-trained model\n",
    "    # classifier = LizardClassifier(model_dir=model_save_dir)\n",
    "    \n",
    "    # # Predict class for a new image\n",
    "    # new_image_path = \"path/to/new_lizard_image.png\"\n",
    "    # predicted_class = classifier.predict(new_image_path)\n",
    "    # print(f\"Predicted lizard class: {predicted_class}\")\n",
    "    \n",
    "    # # Get class probabilities if needed\n",
    "    # class_probabilities = classifier.predict_proba(new_image_path)\n",
    "    # print(\"Class probabilities:\")\n",
    "    # for class_name, probability in class_probabilities.items():\n",
    "    #     print(f\"{class_name}: {probability:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# if want to classify a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished! Extracted lizards saved to D:/Desktop/5243Bianca/Final Project/test_images/extracted_lizards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_lizard(original_img_path, mask_img_path, output_path):\n",
    "    \"\"\"\n",
    "    Extract lizard from original image using the mask and save with transparent background\n",
    "    \n",
    "    Args:\n",
    "        original_img_path: Path to the original JPG image\n",
    "        mask_img_path: Path to the binary mask PNG image\n",
    "        output_path: Path to save the extracted lizard with transparent background\n",
    "    \"\"\"\n",
    "    # Read the original image and mask\n",
    "    original = cv2.imread(original_img_path)\n",
    "    mask = cv2.imread(mask_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Check if images were loaded properly\n",
    "    if original is None:\n",
    "        print(f\"Error: Could not load original image {original_img_path}\")\n",
    "        return\n",
    "    if mask is None:\n",
    "        print(f\"Error: Could not load mask image {mask_img_path}\")\n",
    "        return\n",
    "    \n",
    "    # Resize mask if dimensions don't match\n",
    "    if original.shape[:2] != mask.shape[:2]:\n",
    "        mask = cv2.resize(mask, (original.shape[1], original.shape[0]))\n",
    "    \n",
    "    # Create an alpha channel (transparency) from the mask\n",
    "    # Convert to binary mask if not already (values 0 or 255)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Convert BGR to BGRA (add alpha channel)\n",
    "    rgba = cv2.cvtColor(original, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    # Set alpha channel based on mask (255 for lizard, 0 for background)\n",
    "    rgba[:, :, 3] = binary_mask\n",
    "    \n",
    "    # Save the result with transparency\n",
    "    cv2.imwrite(output_path, rgba)\n",
    "    \n",
    "def process_all_images(original_dir, mask_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all images in the directories\n",
    "    \n",
    "    Args:\n",
    "        original_dir: Directory containing original JPG images\n",
    "        mask_dir: Directory containing mask PNG images\n",
    "        output_dir: Directory to save output images\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of mask files\n",
    "    mask_files = [f for f in os.listdir(mask_dir) if f.endswith('_mask.png')]\n",
    "    \n",
    "    for mask_file in tqdm(mask_files, desc=\"Processing images\"):\n",
    "        # Extract base name from mask (remove _mask.png)\n",
    "        base_name = mask_file.replace('_raw_mask.png', '')\n",
    "        \n",
    "        # Find corresponding original file\n",
    "        original_file = f\"{base_name}.JPG\"\n",
    "        \n",
    "        # Build full paths\n",
    "        original_path = os.path.join(original_dir, original_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_extracted.png\")\n",
    "        \n",
    "        # Check if original file exists\n",
    "        if os.path.exists(original_path):\n",
    "            extract_lizard(original_path, mask_path, output_path)\n",
    "        else:\n",
    "            # Try with lowercase extension\n",
    "            original_file = f\"{base_name}.jpg\"\n",
    "            original_path = os.path.join(original_dir, original_file)\n",
    "            if os.path.exists(original_path):\n",
    "                extract_lizard(original_path, mask_path, output_path)\n",
    "            else:\n",
    "                print(f\"Warning: Could not find original image for mask {mask_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory paths - update these according to your file structure\n",
    "    original_dir = \"D:/Desktop/5243Bianca/Final Project/Dorsal/Dorsal\"  # Where the original JPG files are located\n",
    "    mask_dir = \"D:/Desktop/5243Bianca/Final Project/test_images/result\"  # Where the mask PNG files are located\n",
    "    output_dir = \"D:/Desktop/5243Bianca/Final Project/test_images/extracted_lizards\"  # Where to save the extracted lizards\n",
    "    \n",
    "    process_all_images(original_dir, mask_dir, output_dir)\n",
    "    print(f\"Finished! Extracted lizards saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted lizard class: YQ14\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "classifier = LizardClassifier(model_dir=model_save_dir)\n",
    "\n",
    "# Predict class for a new image\n",
    "new_image_path = \"D:/Desktop/5243Bianca/Final Project/test_images/extracted_lizards/IMG_1417_extracted.png\"\n",
    "predicted_class = classifier.predict(new_image_path)\n",
    "print(f\"Predicted lizard class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted lizard class: YQ14\n"
     ]
    }
   ],
   "source": [
    "new_image_path = \"D:/Desktop/5243Bianca/Final Project/test_images/extracted_lizards/IMG_1429_extracted.png\"\n",
    "predicted_class = classifier.predict(new_image_path)\n",
    "print(f\"Predicted lizard class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dxtorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
